{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Test on Old Shapes Dataset\n",
    "\n",
    "Run the Mask R-CNN net in inference mode, with the additional PCILayer that generates the context-based tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:41:55.808345Z",
     "start_time": "2018-06-18T16:41:44.768808Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " windows  Windows\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " Shapes Per Image:  7\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\newshape_fcn\\shapes20180618T1841\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  1000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (1, 4092)\n",
      "     Deltas :  (1, 4092, 4)\n",
      "     Anchors:  (1, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (1, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 1000, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 1000, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 1000, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 1000, 7)\n",
      "     mrcnn_class_probs    output shape is :  (?, 1000, 7)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 1000, 28)\n",
      "   mrcnn_bbox           output shape is :  (?, 1000, 7, 4)\n",
      "\n",
      ">>> Detection Layer (Inference Mode)\n",
      "    Detection Layer : call()  <class 'list'> 4\n",
      "     rpn_proposals_roi  : (1, ?, ?) (1, ?, ?) (None, 1000, 4)\n",
      "     mrcnn_class.shape  : (?, 1000, 7) (?, 1000, 7) (None, 1000, 7)\n",
      "     mrcnn_bboxes.shape : (?, 1000, 7, 4) (?, 1000, 7, 4) (None, 1000, 7, 4)\n",
      "     input_image_meta   : (?, ?) (?, ?) (None, None)\n",
      "<<<  shape of DETECTIONS :  (None, 100, 6)  Keras tensor  True\n",
      "<<<  shape of DETECTION_BOXES :  (None, 100, 4)  Keras tensor  True\n",
      "\n",
      ">>> CHM Inference  \n",
      "   > CHM Inference Layer: call  <class 'list'> 3\n",
      "     mrcnn_class.shape    : (None, 1000, 7)\n",
      "     mrcnn_bbox.shape     : (None, 1000, 7, 4)\n",
      "     detections.shape     : (None, 100, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  100\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 1000, 7)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 1000, 7, 4) (?, 1000, 7, 4)\n",
      "    input_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(?,), dtype=int32) None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 100 and 1000. Shapes are [1,100] and [?,1000].\n\tFrom merging shape 1 with other shapes. for 'cntxt_layer/stack' (op: 'Pack') with input shapes: [1,100], [1,100], [?,1000].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 100 and 1000. Shapes are [1,100] and [?,1000].\n\tFrom merging shape 1 with other shapes. for 'cntxt_layer/stack' (op: 'Pack') with input shapes: [1,100], [1,100], [?,1000].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-076c4e4639c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel_file\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;34m'E:\\\\Models\\\\newshape_fcn\\\\\\mask_rcnn_shapes_0589.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'newshape_fcn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_newshapes_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\prep_notebook.py\u001b[0m in \u001b[0;36mprep_newshapes_test\u001b[1;34m(init_with, FCN_layers, batch_sz, epoch_steps, folder_name)\u001b[0m\n\u001b[0;32m    188\u001b[0m                               \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                               \u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                               FCN_layers = FCN_layers )\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' COCO Model Path       : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, config, model_dir, FCN_layers)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFCN_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mode, config, FCN_layers)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;31m##----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[0mpr_hm_norm\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mpr_hm_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr_hm\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mCHMLayerInference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cntxt_layer'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmrcnn_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrcnn_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetection_boxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;31m# pr_hm =  PCILayerTF(config, name = 'cntxt_layer') \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\chm_inf_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0mpred_tensor\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mbuild_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrcnn_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrcnn_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m         \u001b[0mpred_cls_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pred_cls_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;31m# pred_heatmap  = build_heatmap_inference(detections, self.config, names = ['detections'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\chm_inf_layer.py\u001b[0m in \u001b[0;36mbuild_predictions\u001b[1;34m(norm_input_rois, mrcnn_class, mrcnn_bbox, config)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#     print('    pred_classes_exp : ', pred_classes_exp.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mgather_ind\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_grid\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbbox_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mpred_scores\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmrcnn_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgather_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mpred_deltas\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmrcnn_bbox\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mgather_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m    937\u001b[0m                                                       expanded_num_dims))\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_pack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   3748\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3749\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3750\u001b[1;33m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   3751\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3752\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3271\u001b[0m         op_def=op_def)\n\u001b[0;32m   3272\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3273\u001b[1;33m                            compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3311\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3313\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3314\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3315\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2499\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2500\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2472\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2474\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2475\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2404\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 100 and 1000. Shapes are [1,100] and [?,1000].\n\tFrom merging shape 1 with other shapes. for 'cntxt_layer/stack' (op: 'Pack') with input shapes: [1,100], [1,100], [?,1000]."
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_newshapes_test\n",
    "import matplotlib.pyplot as plt\n",
    "# model_file  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2192.h5'\n",
    "model_file  = 'E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\\\mask_rcnn_shapes_4044.h5'\n",
    "# model_file  = 'E:\\\\Models\\\\mrcnn_oldshape_test_logs\\\\mask_rcnn_shapes_3877.h5'\n",
    "# model_file   = 'E:\\Models\\mrcnn_logs\\TESTshapes20180511T1742\\mask_rcnn_shapes_0023.h5'\n",
    "\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "\n",
    "model_file  = 'E:\\\\Models\\\\newshape_fcn\\\\\\mask_rcnn_shapes_0589.h5'\n",
    "folder_name = 'newshape_fcn'\n",
    "model, dataset_test, test_generator, inference_config = prep_newshapes_test(init_with = model_file, FCN_layers = True, batch_sz = 1, folder_name = folder_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T15:27:38.903494Z",
     "start_time": "2018-06-05T15:27:38.671072Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:02:55.002435Z",
     "start_time": "2018-06-05T17:02:54.760008Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:29:16.625702Z",
     "start_time": "2018-06-05T17:29:16.268658Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import pprint\n",
    "from mrcnn.utils import log\n",
    "pp = pprint.PrettyPrinter(indent=4, width=100)\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    load_image_gt(dataset_test, inference_config, image_id, use_mini_mask=False)\n",
    "    \n",
    "\n",
    "print('Image Id :', image_id)    \n",
    "shape_list = dataset_test.image_info[image_id]['shapes']\n",
    "pp.pprint(shape_list)\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "print(image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "print(\" 1: person   2: car  3: sun  4: building  5: tree  6: cloud \")\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_test.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:29:23.086423Z",
     "start_time": "2018-06-05T17:29:21.246344Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:31:00.643525Z",
     "start_time": "2018-06-05T17:31:00.182730Z"
    }
   },
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "print('  rois       : ', r['rois'])\n",
    "\n",
    "print('  class ids  : ', r['class_ids'])\n",
    "print('  class names: ', dataset_test.class_names)\n",
    "print('  scores     : ', r['scores'])\n",
    "visualize.display_instances_wo_mask(original_image, r['rois'],r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": false
   },
   "source": [
    "### Run generator to create images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:20:07.099459Z",
     "start_time": "2018-06-05T17:20:07.087492Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(test_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(inference_config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    mask, class_ids = dataset_test.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T15:45:40.489432Z",
     "start_time": "2018-06-05T15:45:35.484051Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(test_generator)\n",
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "print(len(model_output))\n",
    " \n",
    "for i in model_output:\n",
    "    print( i.shape)\n",
    "# print('FCN Normalized Loss is :', fcn_normalized_loss)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:07:51.476311Z",
     "start_time": "2018-06-05T16:07:51.250905Z"
    }
   },
   "outputs": [],
   "source": [
    "detections                = model_output[0]          # layer:  0   shape: (16, 100, 6)\n",
    "rpn_proposal_rois         = model_output[1]          # layer:  1   shape: (16, 1000, 4)\n",
    "rpn_class                 = model_output[2]          # layer:  2   shape: (16, 4092, 2)\n",
    "rpn_bbox                  = model_output[3]          # layer:  3   shape: (16, 4092, 4)\n",
    "mrcnn_class               = model_output[4]          # layer:  4   shape: (16, 1000, 4)\n",
    "mrcnn_bbox                = model_output[5]          # layer:  5   shape: (16, 1000, 4, 4)\n",
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:45:37.969281Z",
     "start_time": "2018-06-05T16:45:37.735878Z"
    }
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "print(rpn_roi_proposals.shape)\n",
    "print(mrcnn_class.shape)\n",
    "print(mrcnn_bbox.shape)\n",
    "print(input_image_meta.shape)\n",
    "print(input_image.shape , input_image_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Inference Detection Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:19:58.246489Z",
     "start_time": "2018-06-05T16:19:58.017103Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils import parse_image_meta, apply_box_deltas\n",
    "a1, a2, windows, a4 =  parse_image_meta(input_image_meta)\n",
    "print(windows)\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:14:58.298738Z",
     "start_time": "2018-06-05T16:14:58.073330Z"
    }
   },
   "outputs": [],
   "source": [
    "# for b in range(self.config.BATCH_SIZE):\n",
    "#     _, _, window, _ =  parse_image_meta(image_meta)\n",
    "b=0\n",
    "print(rpn_proposal_rois[b].shape, mrcnn_class[b].shape, mrcnn_bbox[b].shape)\n",
    "\n",
    "# detections = refine_detections(rois[b], mrcnn_class[b], mrcnn_bbox[b], window[b], self.config)\n",
    "\n",
    "rois = rpn_proposal_rois[b]\n",
    "probs = mrcnn_class[b]\n",
    "deltas = mrcnn_bbox[b]\n",
    "window = windows[b]\n",
    "config = inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:15:22.461101Z",
     "start_time": "2018-06-05T16:15:22.225731Z"
    }
   },
   "outputs": [],
   "source": [
    "##  1. Find Class IDs with higest scores for each per ROI\n",
    "class_ids       = np.argmax(probs, axis=1)\n",
    "print(class_ids)\n",
    "print(probs[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:11:49.448825Z",
     "start_time": "2018-06-05T16:11:49.219436Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  1. Find Class IDs with higest scores for each per ROI\n",
    "class_ids       = np.argmax(probs, axis=1)\n",
    "print(class_ids[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:17:31.207769Z",
     "start_time": "2018-06-05T16:17:30.978372Z"
    }
   },
   "outputs": [],
   "source": [
    "##  2. Get Class probability(score) and bbox delta of the top class of each ROI\n",
    "print(class_ids.shape)\n",
    "print(deltas.shape)\n",
    "class_scores    =  probs[np.arange(class_ids.shape[0]), class_ids]\n",
    "deltas_specific = deltas[np.arange(deltas.shape[0])   , class_ids]\n",
    "print(class_scores.shape)\n",
    "print(deltas_specific.shape)\n",
    "\n",
    "print(class_scores[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:32:42.682978Z",
     "start_time": "2018-06-05T16:32:42.441582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shape: [boxes, (y1, x1, y2, x2)] in normalized coordinates\n",
    "refined_rois    = apply_box_deltas(rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "\n",
    "##  4. Convert the refined roi coordiates from normalized to image domain\n",
    "# TODO: better to keep them normalized until later   \n",
    "height, width   = config.IMAGE_SHAPE[:2]\n",
    "refined_rois   *= np.array([height, width, height, width])\n",
    "\n",
    "##  5.  Clip boxes to image window\n",
    "refined_rois    = clip_to_window(window, refined_rois)\n",
    "\n",
    "##  6.  Round and cast to int since we're deadling with pixels now\n",
    "refined_rois    = np.rint(refined_rois).astype(np.int32)\n",
    "\n",
    "##  7.  TODO: Filter out boxes with zero area\n",
    "\n",
    "##  8.  Filter out background boxes\n",
    "keep = np.where(class_ids > 0)[0]\n",
    "scores = np.where(class_scores >= config.DETECTION_MIN_CONFIDENCE)[0]\n",
    "# Filter out low confidence boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:35:08.713378Z",
     "start_time": "2018-06-05T16:35:08.475003Z"
    }
   },
   "outputs": [],
   "source": [
    "print(class_ids[:40])\n",
    "print(class_scores[:40])\n",
    "print(keep[:20])\n",
    "print(scores[:20])\n",
    "print(class_ids[keep[:20]])\n",
    "print(class_scores[scores[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:33:33.623691Z",
     "start_time": "2018-06-05T16:33:33.393306Z"
    }
   },
   "outputs": [],
   "source": [
    "keep1 = np.intersect1d(keep, scores )\n",
    "print(keep1.size)\n",
    "print(keep1[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:37:50.437792Z",
     "start_time": "2018-06-05T16:37:50.216301Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_nms_class_ids = class_ids[keep1]\n",
    "pre_nms_scores    = class_scores[keep1]\n",
    "pre_nms_rois      = refined_rois[keep1]\n",
    "nms_keep          = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:42:57.526373Z",
     "start_time": "2018-06-05T16:42:57.290005Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pre_nms_class_ids[:20])\n",
    "print(pre_nms_scores[:20])\n",
    "print(np.unique(pre_nms_class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with zeros if detections < DETECTION_MAX_INSTANCES\n",
    "gap = self.config.DETECTION_MAX_INSTANCES - detections.shape[0]\n",
    "assert gap >= 0\n",
    "if gap > 0:\n",
    "    detections = np.pad(detections, [(0, gap), (0, 0)], 'constant', constant_values=0)\n",
    "detections_batch.append(detections)\n",
    "\n",
    "# Stack detections and cast to float32\n",
    "# TODO: track where float64 is introduced\n",
    "detections_batch = np.array(detections_batch).astype(np.float32)\n",
    "# Reshape output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:05:54.706908Z",
     "start_time": "2018-06-05T16:05:54.467566Z"
    }
   },
   "outputs": [],
   "source": [
    "def refine_detections(rois, probs, deltas, window, config):\n",
    "    '''\n",
    "    Refine classified proposals and filter overlaps and return final detections.\n",
    "\n",
    "    Inputs:\n",
    "    ------\n",
    "        \n",
    "    rois:           rpn_rois    - [N, (y1, x1, y2, x2)] in normalized coordinates\n",
    "    probs:          mrcnn_class - [N, num_classes]. Class probabilities.\n",
    "    deltas:         mrcnn_bbox  - [N, num_classes, (dy, dx, log(dh), log(dw))]. \n",
    "                                  Class-specific bounding box deltas.\n",
    "                                  \n",
    "    window:         (y1, x1, y2, x2) in image coordinates. The part of the image\n",
    "                    that contains the image excluding the padding.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    detections      [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    '''\n",
    "\n",
    "    \n",
    "    ##  1. Find Class IDs with higest scores for each per ROI\n",
    "    class_ids       = np.argmax(probs, axis=1)\n",
    "    print(class_ids)\n",
    "    ##  2. Get Class probability(score) and bbox delta of the top class of each ROI\n",
    "    class_scores    =  probs[np.arange(class_ids.shape[0]), class_ids]\n",
    "    deltas_specific = deltas[np.arange(deltas.shape[0])   , class_ids]\n",
    "    \n",
    "    ##  3. Apply bounding box delta to the corrsponding rpn_proposal\n",
    "    # Shape: [boxes, (y1, x1, y2, x2)] in normalized coordinates\n",
    "    refined_rois    = apply_box_deltas(rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "    \n",
    "    ##  4. Convert the refined roi coordiates from normalized to image domain\n",
    "    # TODO: better to keep them normalized until later   \n",
    "    height, width   = config.IMAGE_SHAPE[:2]\n",
    "    refined_rois   *= np.array([height, width, height, width])\n",
    "    \n",
    "    ##  5.  Clip boxes to image window\n",
    "    refined_rois    = clip_to_window(window, refined_rois)\n",
    "    \n",
    "    ##  6.  Round and cast to int since we're deadling with pixels now\n",
    "    refined_rois    = np.rint(refined_rois).astype(np.int32)\n",
    "\n",
    "    ##  7.  TODO: Filter out boxes with zero area\n",
    "\n",
    "    ##  8.  Filter out background boxes\n",
    "    keep = np.where(class_ids > 0)[0]\n",
    "    # Filter out low confidence boxes\n",
    "    if config.DETECTION_MIN_CONFIDENCE:\n",
    "        keep = np.intersect1d(keep, np.where(class_scores >= config.DETECTION_MIN_CONFIDENCE)[0])\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ##  9.  Apply per-class NMS\n",
    "    ##----------------------------------------------------------------------------\n",
    "    pre_nms_class_ids = class_ids[keep]\n",
    "    pre_nms_scores    = class_scores[keep]\n",
    "    pre_nms_rois      = refined_rois[keep]\n",
    "    nms_keep          = []\n",
    "    # print(' apply per class nms')    \n",
    "    for class_id in np.unique(pre_nms_class_ids):\n",
    "        # Pick detections of this class\n",
    "        ixs = np.where(pre_nms_class_ids == class_id)[0]\n",
    "\n",
    "        # print('class_id : ', class_id)\n",
    "        # print('pre_nms_rois.shape:', pre_nms_rois[ixs].shape)\n",
    "        # pp.pprint(pre_nms_rois[ixs])\n",
    "        # print('pre_nms_scores.shape :', pre_nms_scores[ixs].shape)\n",
    "        # pp.pprint(pre_nms_scores[ixs])    \n",
    "        # Apply NMS\n",
    "        class_keep = non_max_suppression(pre_nms_rois[ixs], \n",
    "                                         pre_nms_scores[ixs],\n",
    "                                         config.DETECTION_NMS_THRESHOLD)\n",
    "        # Map indicies\n",
    "        class_keep = keep[ixs[class_keep]]\n",
    "        nms_keep   = np.union1d(nms_keep, class_keep)\n",
    "    \n",
    "    keep = np.intersect1d(keep, nms_keep).astype(np.int32)\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ## 10.  Keep top detections\n",
    "    ##----------------------------------------------------------------------------\n",
    "    roi_count = config.DETECTION_MAX_INSTANCES\n",
    "    top_ids   = np.argsort(class_scores[keep])[::-1][:roi_count]\n",
    "    keep      = keep[top_ids]\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    ## 11.  Arrange output as [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    ##      Coordinates are in image domain.\n",
    "    ##----------------------------------------------------------------------------\n",
    "    result = np.hstack((refined_rois[keep],\n",
    "                        class_ids   [keep][..., np.newaxis],\n",
    "                        class_scores[keep][..., np.newaxis]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:05:54.706908Z",
     "start_time": "2018-06-05T16:05:54.467566Z"
    }
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Detection Layer\n",
    "############################################################\n",
    "\n",
    "def clip_to_window(window, boxes):\n",
    "    '''\n",
    "    window: (y1, x1, y2, x2). The window in the image we want to clip to.\n",
    "    boxes: [N, (y1, x1, y2, x2)]\n",
    "    '''\n",
    "    \n",
    "    boxes[:, 0] = np.maximum(np.minimum(boxes[:, 0], window[2]), window[0])\n",
    "    boxes[:, 1] = np.maximum(np.minimum(boxes[:, 1], window[3]), window[1])\n",
    "    boxes[:, 2] = np.maximum(np.minimum(boxes[:, 2], window[2]), window[0])\n",
    "    boxes[:, 3] = np.maximum(np.minimum(boxes[:, 3], window[3]), window[1])\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:47:59.541625Z",
     "start_time": "2018-06-05T16:47:59.296263Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_image = train_batch_x\n",
    "results = model.detect(original_image, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T11:56:20.774651Z",
     "start_time": "2018-05-10T11:56:20.439754Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "print('  rois       : ', r['rois'])\n",
    "print('  masks      : ', r['masks'].shape)\n",
    "print('  class ids  : ', r['class_ids'])\n",
    "print('  class names: ', dataset_test.class_names)\n",
    "print('  scores     : ', r['scores'])\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T11:57:47.846606Z",
     "start_time": "2018-05-10T11:57:22.672337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "import  mrcnn.utils as utils \n",
    "\n",
    "image_ids = np.random.choice(dataset_test.image_ids, 100)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        load_image_gt(dataset_test, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(utils.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulation of `detect()` routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T16:56:16.446332Z",
     "start_time": "2018-06-05T16:56:14.479593Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('>>> model detect()')\n",
    "print(model.config.BATCH_SIZE)\n",
    "images = train_batch_x[0]\n",
    "print(len(input_images))\n",
    "verbose = 1\n",
    "# images  = [original_image]\n",
    "assert model.mode   == \"inference\", \"Create model in inference mode.\"\n",
    "assert len(images) == model.config.BATCH_SIZE, \"len(images) must be equal to BATCH_SIZE\"\n",
    "\n",
    "if verbose:\n",
    "    log(\"Processing {} images\".format(len(images)))\n",
    "    for image in images:\n",
    "        log(\"image\", image)\n",
    "\n",
    "# Mold inputs to format expected by the neural network\n",
    "molded_images, image_metas, windows = model.mold_inputs(images)\n",
    "if verbose:\n",
    "    log(\"molded_images\", molded_images)\n",
    "    log(\"image_metas\"  , image_metas)\n",
    "\n",
    "## Run object detection pipeline\n",
    "# print('    call predict()')\n",
    "detections, rpn_rois, rpn_class, rpn_bbox,\\\n",
    "            mrcnn_class, mrcnn_bbox \\\n",
    "                      =  model.keras_model.predict([molded_images, image_metas], verbose=0)\n",
    "\n",
    "print('    return from  predict()')\n",
    "print('    Length of detections : ', len(detections))\n",
    "print('    Length of rpn_rois   : ', len(rpn_rois   ))\n",
    "print('    Length of rpn_class  : ', len(rpn_class  ))\n",
    "print('    Length of rpn_bbox   : ', len(rpn_bbox   ))\n",
    "print('    Length of mrcnn_class: ', len(mrcnn_class))\n",
    "print('    Length of mrcnn_bbox : ', len(mrcnn_bbox ))\n",
    "# print('    Length of mrcnn_mask : ', len(mrcnn_mask ))\n",
    "\n",
    "####  detection array layout is `[ y1, x1, y2, x2, class, score]`\n",
    "\n",
    "detections[0].shape\n",
    "print(detections[0])\n",
    "\n",
    "## Process detections\n",
    "results = []\n",
    "for i, image in enumerate(images):\n",
    "    final_rois, final_class_ids, final_scores  =\\\n",
    "        model.unmold_detections(detections[i], \n",
    "                               image.shape  ,\n",
    "                               windows[i])\n",
    "    results.append({\n",
    "        \"rois\"     : final_rois,\n",
    "        \"class_ids\": final_class_ids,\n",
    "        \"scores\"   : final_scores,\n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:12:25.863446Z",
     "start_time": "2018-06-05T17:12:25.631052Z"
    }
   },
   "outputs": [],
   "source": [
    "original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T17:16:46.871340Z",
     "start_time": "2018-06-05T17:16:44.311189Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(config.BATCH_SIZE)   :\n",
    "    r = results[i]\n",
    "    print('  rois       : ', r['rois'])\n",
    "    print('  class ids  : ', r['class_ids'])\n",
    "    print('  class names: ', dataset_test.class_names)\n",
    "    print('  scores     : ', r['scores'])\n",
    "    visualize.display_instances_wo_mask(input_image[i], r['rois'], r['class_ids'], dataset_test.class_names, r['scores'], figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
