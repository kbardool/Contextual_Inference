{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train modified model on old shapes dataset\n",
    "\n",
    "### the modified model does not include any mask related heads or losses \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T14:10:02.827287Z",
     "start_time": "2018-06-06T14:09:11.121575Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " windows  Windows\n",
      "Tensorflow Version: 1.4.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\models\\mrcnn_oldshape_train_logs\\shapes20180613T1232\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     C1 Shape: (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "     C2 Shape:  (?, 32, 32, 256) (?, 32, 32, 256)\n",
      "     C3 Shape:  (?, 16, 16, 512) (?, 16, 16, 512)\n",
      "     C4 Shape:  (?, 8, 8, 1024) (?, 8, 8, 1024)\n",
      "     C5 Shape:  (?, 4, 4, 2048) (?, 4, 4, 2048)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/rpn_class_logits:0\n",
      "      rpn_class/rpn_class:0\n",
      "      rpn_bbox/rpn_bbox:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (16, 4092)\n",
      "     Deltas :  (16, 4092, 4)\n",
      "     Anchors:  (16, 4092, 4)\n",
      "     Boxes shape / type after processing: \n",
      "     Output: Prposals shape :  (16, ?, ?) (16, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (16, ?, ?) (16, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (16, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (16, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (16, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (16, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (16, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (16, ?, ?) (None, 32, 4)\n",
      "     tgt_class_ids.shape  : (16, ?) (None, 32)\n",
      "     gt_bboxes.shape      : (16, ?, ?) (None, 32, 4)\n",
      " config image shape:  [128 128   3] h: 128 w: 128\n",
      "\n",
      "  > build_predictions()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    input_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (16, None, 4)\n",
      "    pred_array        (16, 32, 6)\n",
      "scatter_ind <class 'tensorflow.python.framework.ops.Tensor'> shape (16, 32, 3)\n",
      "    pred_scatter shape is  (16, 4, 32, 6)\n",
      "(16, 4, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "\n",
      "    num_rois           :  32 (building  gt_tensor )\n",
      "    gt_class_ids shape :  (16, ?)\n",
      "    gt_bboxes.shape    :  (16, ?, 4)\n",
      "    gt_classes_exp shape  (16, ?, 1)\n",
      "    gt_scores_exp shape  (16, ?, 1)\n",
      "    gt_array shape : (16, 32, 7) (16, 32, 7)\n",
      "     gt_tensor final shape  :  (16, 4, 32, ?)\n",
      "\n",
      " \n",
      "  > NEW build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (16, 4, 32, 6)\n",
      "    num of bboxes per class is :  32\n",
      "    pt2_sum shape  (16, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    X/Y shapes : (128, 128) (128, 128)\n",
      "    Ones:     (?, 1, 1)\n",
      "    ones_exp * X (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    ones_exp * Y (?, 1, 1) * (128, 128) =  (?, 128, 128)\n",
      "    before transpse  (?, 128, 128, 2)\n",
      "    after transpose  (128, 128, ?, 2)\n",
      "     Prob_grid shape before tanspose:  (128, 128, ?)\n",
      "     Prob_grid shape after tanspose:  (?, 128, 128)\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, ?, 2)\n",
      "    << output probabilities shape: (?, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    pt2_ind shape   :  (?, 3)\n",
      "    prob_grid shape :  (?, 128, 128)\n",
      "    gauss_scatt     :  (16, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian_sum shape     :  (16, 4, 128, 128) Keras tensor  False\n",
      "    gauss L2 norm   :  (16, 4, 128, 128)  Keras tensor  False\n",
      "\n",
      "    normalization ------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduce_max() got an unexpected keyword argument 'keepdims'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-61a4916c266e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# model_file = \"E:\\Models\\mrcnn_oldshape_train_logs\\TrainMRCNN\\mask_rcnn_shapes_1418.h5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# model_file = \"E:\\Models\\mrcnn_oldshape_train_logs\\shapes20180606T1150\\mask_rcnn_shapes_0008.h5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_oldshapes_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'last'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\prep_notebook.py\u001b[0m in \u001b[0;36mprep_oldshapes_train\u001b[1;34m(init_with, FCN_layers, batch_sz)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mKB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFCN_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' COCO Model Path       : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, config, model_dir, FCN_layers)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFCN_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFCN_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\model_mod.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mode, config, FCN_layers)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mpr_hm\u001b[0m      \u001b[1;33m,\u001b[0m \u001b[0mgt_hm\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[1;33m=\u001b[0m  \u001b[0mCHMLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cntxt_layer'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmrcnn_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrcnn_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_rois\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_class_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_gt_boxes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\chm_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[0mgt_cls_cnt\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mKL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gt_cls_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mpr_hm_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr_hm_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr_hm\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mbuild_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'pred_heatmap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[0mgt_hm_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_hm_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_hm\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mbuild_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'gt_heatmap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\git_projs\\MRCNN2\\mrcnn\\chm_layer.py\u001b[0m in \u001b[0;36mbuild_heatmap\u001b[1;34m(in_tensor, config, names)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n    normalization ------------------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mgauss_norm\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mgauss_sum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauss_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m     \u001b[0mgauss_norm\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauss_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauss_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgauss_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'    gauss norm   : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgauss_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m   \u001b[1;33m,\u001b[0m\u001b[1;34m' Keras tensor '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauss_norm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reduce_max() got an unexpected keyword argument 'keepdims'"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "import keras.backend as KB\n",
    "import numpy as np\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.utils       import mask_string\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.prep_notebook import prep_oldshapes_train, load_model\n",
    "# model_file = \"E:\\Models\\mrcnn_oldshape_train_logs\\TrainMRCNN\\mask_rcnn_shapes_1418.h5\"\n",
    "# model_file = \"E:\\Models\\mrcnn_oldshape_train_logs\\shapes20180606T1150\\mask_rcnn_shapes_0008.h5\"\n",
    "model, dataset_train, dataset_val, train_generator, val_generator, config = prep_oldshapes_train(init_with = 'last', FCN_layers = True, batch_sz = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:06:05.829087Z",
     "start_time": "2018-06-05T14:06:05.602689Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T16:42:44.455860Z",
     "start_time": "2018-05-28T16:42:43.010024Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.prep_notebook import load_model\n",
    "load_model(model, init_with='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "### Training FPN, RPN and MRCNN heads using  Keras.model.fit_generator()\n",
    "\n",
    "print(config.BATCH_SIZE)\n",
    "print(model.config.BATCH_SIZE)\n",
    "print(model.config.LEARNING_RATE)\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:37:28.251199Z",
     "start_time": "2018-06-05T21:11:11.215070Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "## Last run prior to FCN training was 3699, last checkpoint was 3892  ...start at 3899\n",
    "\n",
    "train_layers = [ 'mrcnn', 'fpn','rpn']\n",
    "loss_names   = [ \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "model.epoch = 1233\n",
    "model.config.LEARNING_RATE = 1.0e-4\n",
    "model.config.STEPS_PER_EPOCH = 7\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=model.config.LEARNING_RATE, \n",
    "            epochs_to_run =3000, \n",
    "#             epochs = 25,            \n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            min_LR = 1.0e-6,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train FCN head layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T12:39:18.755289Z",
     "start_time": "2018-06-07T12:34:14.060639Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "\n",
    "## Last run prior to FCN training was 3699, last checkpoint was 3892\n",
    "\n",
    "train_layers = ['fcn']\n",
    "loss_names   = [  \"fcn_norm_loss\"]\n",
    "model.epoch = 1668\n",
    "model.config.LEARNING_RATE = 1.0e-4\n",
    "model.config.STEPS_PER_EPOCH = 8 \n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=model.config.LEARNING_RATE, \n",
    "            epochs_to_run = 500, \n",
    "#             epochs = 25,            \n",
    "#             batch_size = 6,\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            min_LR = 1.0e-9\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:17:32.353508Z",
     "start_time": "2018-05-20T18:17:32.121048Z"
    }
   },
   "outputs": [],
   "source": [
    "model.keras_model.losses\n",
    "print(model.keras_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")\n",
    "\n",
    "# train_layers = ['fcn']\n",
    "# loss_names   = [  \"fcn_norm_loss\"]\n",
    "# model.epoch = 208\n",
    "# model.config.LEARNING_RATE = 1.0e-4\n",
    "# model.config.STEPS_PER_EPOCH = 8 \n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=model.config.LEARNING_RATE, \n",
    "#             epochs_to_run = 500, \n",
    "# #             epochs = 25,            \n",
    "# #             batch_size = 6,\n",
    "# #             steps_per_epoch = 0 \n",
    "#             layers = train_layers,\n",
    "#             losses = loss_names,\n",
    "#             min_LR = 1.0e-7\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_post_training.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:25:16.962148Z",
     "start_time": "2018-05-20T18:25:16.737938Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:10:55.871863Z",
     "start_time": "2018-06-05T14:10:51.289152Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:10:58.357215Z",
     "start_time": "2018-06-05T14:10:58.128846Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T14:11:29.002604Z",
     "start_time": "2018-06-05T14:11:21.360692Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n",
    "# model_output = get_layer_output_1(model.keras_model, train_batch_x, [ 26], 1)\n",
    "\n",
    "print(len(model_output))\n",
    "\n",
    "# rpn_class_loss            = model_output[0]          # layer: 11   shape: (1, 1)\n",
    "# rpn_bbox_loss             = model_output[1]          # layer: 12   shape: (1, 1)\n",
    "# mrcnn_class_loss          = model_output[2]          # layer: 13   shape: (1, 1)\n",
    "# mrcnn_bbox_loss           = model_output[3]          # layer: 14   shape: (1, 1)\n",
    "# fcn_normalized_loss       = model_output[0]          # layer: 26   shape: (1, 1)\n",
    "\n",
    "# print(type(output_rois))\n",
    "for i in model_output:\n",
    "    print( i.shape)\n",
    "# print('FCN Normalized Loss is :', fcn_normalized_loss)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T18:40:52.258442Z",
     "start_time": "2018-05-20T18:40:52.031879Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image      =  train_batch_x[0]\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes    = train_batch_x[5]\n",
    "input_gt_masks     = train_batch_x[6]\n",
    "print(' Input image shape is :', input_image.shape)\n",
    "h, w = input_image.shape[1], input_image.shape[2]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_bboxes = tf.identity(input_gt_bboxes / [h,w,h,w])\n",
    "\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n",
    "print(' input_normlzd_gt_bboxes    ', input_normlzd_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
